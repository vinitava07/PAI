# ğŸ§  Treinamento Inception V3 para ClassificaÃ§Ã£o ALN

Este documento explica como treinar o modelo Inception V3 para classificaÃ§Ã£o de status de linfonodos axilares (ALN) em imagens histolÃ³gicas de cÃ¢ncer de mama.

## ğŸ“‹ VisÃ£o Geral

O sistema classifica patches de imagens histolÃ³gicas em trÃªs categorias:
- **N0**: Sem metÃ¡stase linfonodal
- **N+(1-2)**: 1-2 linfonodos com metÃ¡stase
- **N+(>2)**: Mais de 2 linfonodos com metÃ¡stase

## ğŸ—ï¸ Arquitetura

- **Modelo Base**: Inception V3 prÃ©-treinado no ImageNet
- **EstratÃ©gia**: Transfer Learning com fine-tuning em duas fases
- **Input**: Patches de 299x299 pixels
- **Output**: Probabilidades para 3 classes

## ğŸ“ Estrutura de Dados

```
PAI/
â”œâ”€â”€ patches/                    # DiretÃ³rio com patches organizados por paciente
â”‚   â”œâ”€â”€ 1/                     # Paciente 1
â”‚   â”‚   â”œâ”€â”€ 1_0_0_0.jpg       # Patches do paciente 1
â”‚   â”‚   â”œâ”€â”€ 1_0_0_256.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ 2/                     # Paciente 2
â”‚   â””â”€â”€ ...
â”œâ”€â”€ patient-clinical-data.csv   # Dados clÃ­nicos com ALN status
â””â”€â”€ models/                     # DiretÃ³rio de saÃ­da (criado automaticamente)
```

## ğŸš€ Como Executar

### OpÃ§Ã£o 1: Menu Interativo (Recomendado)

```bash
python run_inception_training.py
```

Escolha uma das opÃ§Ãµes:
1. **Treinamento rÃ¡pido** (5 patches/paciente, ~30 min)
2. **Treinamento mÃ©dio** (10 patches/paciente, ~1-2 horas)
3. **Treinamento completo** (todos patches, ~4-6 horas)

### OpÃ§Ã£o 2: Linha de Comando

```bash
# Treinamento mÃ©dio (recomendado)
python run_inception_training.py --mode medio

# Treinamento rÃ¡pido para testes
python run_inception_training.py --mode rapido

# Treinamento customizado
python run_inception_training.py --mode custom --patches 15 --epochs 40 --batch-size 8
```

### OpÃ§Ã£o 3: Script Direto

```python
from train_inception_v3_improved import InceptionV3ALNClassifier

# Inicializar
classifier = InceptionV3ALNClassifier(
    patches_dir="patches",
    clinical_data_path="patient-clinical-data.csv"
)

# Carregar dados
classifier.load_clinical_data()

# Preparar dataset (80% treino, 20% teste)
datasets = classifier.prepare_dataset(
    max_patches_per_patient=10,  # ou None para todos
    test_size=0.2,
    val_size=0.1
)

# Construir modelo
model = classifier.build_model()

# Treinar
history = classifier.train_model(
    datasets=datasets,
    epochs=30,
    fine_tune_epochs=15
)

# Avaliar
results = classifier.evaluate_model(datasets['test'])
```

## âš™ï¸ ParÃ¢metros Importantes

### PreparaÃ§Ã£o dos Dados
- `max_patches_per_patient`: Limita patches por paciente (None = todos)
- `test_size`: ProporÃ§Ã£o de pacientes para teste (padrÃ£o: 0.2 = 20%)
- `val_size`: ProporÃ§Ã£o para validaÃ§Ã£o do treino (padrÃ£o: 0.1 = 10%)

### Treinamento
- `epochs`: Ã‰pocas para fase 1 (feature extraction)
- `fine_tune_epochs`: Ã‰pocas para fase 2 (fine-tuning)
- `batch_size`: Tamanho do batch (reduzir se houver erro de memÃ³ria)
- `fine_tune_layers`: NÃºmero de camadas a descongelar

## ğŸ“Š DivisÃ£o dos Dados

**IMPORTANTE**: A divisÃ£o Ã© feita por **PACIENTE**, nÃ£o por patch!

```
Total de pacientes: 1058
â”œâ”€â”€ Treino: ~740 pacientes (70%)
â”œâ”€â”€ ValidaÃ§Ã£o: ~106 pacientes (10%)
â””â”€â”€ Teste: ~212 pacientes (20%)
```

Isso garante que:
- âœ… NÃ£o hÃ¡ vazamento de dados entre conjuntos
- âœ… Patches do mesmo paciente ficam no mesmo conjunto
- âœ… AvaliaÃ§Ã£o realista da capacidade de generalizaÃ§Ã£o

## ğŸ¯ Processo de Treinamento

### Fase 1: Feature Extraction
- Modelo base (Inception V3) congelado
- Treina apenas camadas de classificaÃ§Ã£o
- Learning rate: 0.001
- DuraÃ§Ã£o: ~30 Ã©pocas

### Fase 2: Fine-tuning
- Descongela Ãºltimas 100-150 camadas
- Learning rate reduzido: 0.00001
- DuraÃ§Ã£o: ~15-20 Ã©pocas

## ğŸ“ˆ MÃ©tricas e AvaliaÃ§Ã£o

O sistema calcula:
- **Por Patch**: AcurÃ¡cia, PrecisÃ£o, Recall, F1-Score, ROC AUC
- **Por Paciente**: AgregaÃ§Ã£o das prediÃ§Ãµes de todos os patches

### Arquivos de SaÃ­da

```
models/run_YYYYMMDD_HHMMSS/
â”œâ”€â”€ best_model_final.h5          # Modelo treinado
â”œâ”€â”€ training_curves_*.png        # GrÃ¡ficos de treinamento
â”œâ”€â”€ confusion_matrix.png         # Matriz de confusÃ£o
â”œâ”€â”€ roc_curves.png              # Curvas ROC
â”œâ”€â”€ test_metrics.json           # MÃ©tricas detalhadas
â”œâ”€â”€ classification_report.csv    # RelatÃ³rio por classe
â”œâ”€â”€ test_predictions.csv        # PrediÃ§Ãµes no teste
â””â”€â”€ relatorio_final.html        # RelatÃ³rio completo
```

## ğŸ”§ ResoluÃ§Ã£o de Problemas

### Erro de MemÃ³ria GPU
```bash
# Reduzir batch size
python run_inception_training.py --mode medio --batch-size 8
```

### Processo Muito Lento
```bash
# Usar menos patches por paciente
python run_inception_training.py --mode custom --patches 5 --epochs 20
```

### Verificar GPU
```python
import tensorflow as tf
print("GPUs disponÃ­veis:", tf.config.list_physical_devices('GPU'))
```

## ğŸ’¡ Dicas de Uso

1. **Desenvolvimento**: Use modo 'rapido' para testar o pipeline
2. **ProduÃ§Ã£o**: Use modo 'medio' ou 'completo'
3. **MemÃ³ria**: Reduza batch_size se houver erro de GPU
4. **Patches**: Limite patches por paciente para treinos mais rÃ¡pidos

## ğŸ“Š Resultados Esperados

Com configuraÃ§Ã£o padrÃ£o (modo mÃ©dio):
- AcurÃ¡cia: ~75-85%
- AUC: ~0.85-0.92
- Tempo: 1-2 horas com GPU

## ğŸ” AnÃ¡lise dos Resultados

ApÃ³s o treinamento, abra o arquivo `relatorio_final.html` no navegador para visualizar:
- MÃ©tricas detalhadas por classe
- Curvas de treinamento
- Matriz de confusÃ£o
- Curvas ROC
- AvaliaÃ§Ã£o por paciente

## ğŸ“ Exemplo de Uso Completo

```bash
# 1. Verificar dados
ls patches/ | wc -l  # Deve mostrar 1058 diretÃ³rios

# 2. Executar treinamento mÃ©dio
python run_inception_training.py --mode medio

# 3. Verificar resultados
cd models/run_*/
firefox relatorio_final.html
```

## âš ï¸ ObservaÃ§Ãµes Importantes

1. **GPU Recomendada**: O treinamento Ã© ~10x mais rÃ¡pido com GPU
2. **Dados Balanceados**: O sistema usa class weights automÃ¡ticos
3. **Reprodutibilidade**: Seeds fixas garantem resultados consistentes
4. **ValidaÃ§Ã£o**: Monitora overfitting com early stopping

---

Para mais informaÃ§Ãµes ou problemas, verifique os logs de treinamento no diretÃ³rio de saÃ­da.
